# -*- coding: utf-8 -*-
"""NLP alexa_review.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1q_Su8ik4MjmwAr8xp2C23KTeyaEszzUm

Data Format:
A tab-separated values (TSV) file is a text format whose primary function is to store data in a table structure where each record in the table is recorded as one line of the text file.
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import re
from nltk.corpus import stopwords
from tensorflow.keras.preprocessing.text import Tokenizer
#from tensorflow.keras.preprocessing.sequence import pad_sequences
from sklearn.model_selection import train_test_split
#from tensorflow.keras.layers import Dense,Dropout,LSTM,Embedding
from tensorflow.keras.models import Sequential

import nltk
nltk.download('stopwords')
from nltk.corpus import stopwords

"""The sep parameter is set to '\t', indicating that the file is tab-separated."""

tsv_file_path = "/content/drive/MyDrive/rini_datascience/amazon_alexa.tsv"
df = pd.read_csv(tsv_file_path, sep='\t')
print(df.head())

df = df.drop(["date"],axis=1)

df.feedback.plot(kind="hist",title="Feedback")

df.feedback.value_counts()

df.rating.plot(kind="hist",title="rating")

STOPWORDS=stopwords.words("english")

def clean(x):
    x = x.lower()
    x = re.sub("[^\w\d]"," ",x)
    x = " ".join(t for t in x.split() if t not in STOPWORDS)#removing stopwords
    return x

df["cleaned"] = df["verified_reviews"].apply(lambda x : clean(x))

df.head()

df.cleaned[3]

df.isnull().sum()

num_words = 500

texts = df["cleaned"]

import nltk
nltk.download('punkt')

def tokenize_text(text):
    return nltk.word_tokenize(text)

tokenized_text = df["cleaned"].apply(tokenize_text)

tokenized_text

from sklearn.feature_extraction.text import TfidfVectorizer
vectorizer=TfidfVectorizer(max_features=2000, min_df=5, max_df=0.7, stop_words=STOPWORDS)

x = vectorizer.fit_transform(tokenized_text.apply(lambda x: ' '.join(x)))
#to convert each tokenized list back to a single string

print(x)

dense_matrix = x.toarray()
print(dense_matrix)

y=df['feedback']



y.value_counts()

x_train, x_test, y_train, y_test = train_test_split(dense_matrix,y, test_size=0.20, random_state=42)

from imblearn.over_sampling import SMOTE
smote = SMOTE(sampling_strategy='auto', random_state=42)
x_train,y_train = smote.fit_resample(x_train, y_train)

from sklearn.ensemble import RandomForestClassifier
clf=RandomForestClassifier(n_estimators=250,random_state=0)
clf.fit(x_train,y_train)

y_pred=clf.predict(x_test)

from sklearn.metrics import classification_report,accuracy_score,confusion_matrix

accuracy_score(y_test,y_pred)

confusion_matrix(y_test,y_pred)

report = classification_report(y_test,y_pred)

print(report)

print(clf.predict(vectorizer.transform(['turning into a amatuer nuisance'])))

print(clf.predict(vectorizer.transform(['Wonderful Amazon App to control the Amazon Echo, Dot and Tap Devices.'])))

